# -*- coding: utf-8 -*-
"""SEIR_EoN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bCitMSfYkKQJ7Dvk4KSZygGYVCoC6dzk

# Comparison of SEIR epidemic dynamics resulting from several methods to relax social distancing on a household network structure

- We describe SEIR epidemic dynamics when multiple social distancing relaxation methods are enacted on a N=10000 node network structure that is divided into household clusters. There are two types of edges of the network: (1) within household connections and (2) between household connections. Within each household cluster, all nodes are connected (complete network). Between household connections are randomly added between every two individuals of different households (binomial network). The network can be described as the combination of these two types of connections.
- The SEIR epidemic parameters are roughly assumed to be similar to inferred parameters of the current coronavirus pandemic. Specifically, we assume an average incubation period of 5 days, an average infectious period of 8 days, and an R0 of 2.5.
- This code was originally extended out of Joel C. Miller's code for a simple SEIR epidemic simulation. Joel C. Miller's original code can be found here: https://epidemicsonnetworks.readthedocs.io/en/latest/functions/EoN.Gillespie_simple_contagion.html#EoN.Gillespie_simple_contagion

#Import libraries and set directory to plot results
"""

!pip install EoN
import EoN
import networkx as nx
from collections import defaultdict
import matplotlib.pyplot as plt
import random
import math
import scipy
import numpy as np
import matplotlib.patches as mpatches
import os
import calendar
from os import path
from itertools import product
from datetime import date

random.seed(0)

# Directory to save results ----------------------------------------------------
directory_plots = "/Users/Justin/Philly_Covid/EoN/seir_eon_results/"

"""#Changeable parameters of epidemic and network structure"""

# Network parameters -----------------------------------------------------------
N = 10000 # Number of nodes
type_ld_graph_to_use = "binomial" # "binomial" or "geographic_heterogeneity"
probability_ld_edge = 0.0002 # Used if the ld graph type used is "binomial"
sigma = 0.01 # Used if the ld graph type used is "geographic heterogeneity" -- changes width of Gaussian kernel
prob_unfuse = 0.1 # Probability of unfusing each day after "I" found in a house under voluntary fusing
frac_to_fuse = 1/50 # Initial fraction to fuse
local_weight_transmission = 2
ld_weight_transmission = 1

# Eviction parameters ----------------------------------------------------------
# Format is: list of tuple of format (date_of_eviction, frac_to_fuse) ----------
fusings = [(date(2020, 8, 1), 1/30),
           (date(2020, 9, 1), 1/30),
           (date(2020, 10, 1), 1/30),
           (date(2020, 11, 1), 1/30),
           (date(2020, 12, 1), 1/30),
           (date(2021, 1, 1), 1/30),
           (date(2021, 2, 1), 1/30),
           (date(2021, 3, 1), 1/30),
           (date(2021, 4, 1), 1/30)]

# Epidemic parameters ----------------------------------------------------------
R_0 = 2.5
R_under_SD = 0.85
R_under_easing = 1.1
rate_E_I = 1/5
rate_I_R = 1/8

# Timeline parameters ----------------------------------------------------------
number_of_initial_infected = 5
prev_start_SD = 0.01
sd_date = date(2020, 3, 14)
easing_date = date(2020, 6, 5)
evictions_date = date(2020, 7, 11)
end_date = date(2021, 5, 1)
sd_to_easing = (easing_date - sd_date).days
easing_to_evictions = (evictions_date - easing_date).days
evictions_to_end = (end_date - evictions_date).days

# Simulation parameters --------------------------------------------------------
number_of_simulations = 3

"""# Creating household network structures
- local: network of household edges. Each household is a complete graph, and each household is isolated from each other.
- ld: network of long distance edges between individuals from different households. Binomial graph.
- O: network combination of local and ld.
- SD: network of O that deletes some percent of the ld edges.
- expanded_SD: network of SD that fuses a fraction of the isolated households of local.
- add_back_long_SD: network that adds back a fraction of the long distance edges to the SD network.
- add_back_long_expanded_SD: network that adds back a fraction of the long distance edges to the expanded_SD graph.

## local
- Create local network structure based. The network can qualitatively described as isolated connected components, where each connected component is complete.
"""

def create_local():
    # Household size distribution from the 2010 census data --------------------
    total_house = 118092823
    one_house = 31532469
    two_house = 38634080
    three_house = 19038803
    four_house = 15853234
    five_house = 7638191
    six_house = 3106133
    seven_house = 2289913

    house_size_dist = np.array([one_house,two_house,three_house,four_house,five_house,six_house,seven_house])/total_house

    household_sizes = []

    while sum(household_sizes) < N:
        household_sizes.extend(np.random.choice(np.arange(1,8,1), p=house_size_dist, size=1)) 

    if sum(household_sizes) > N:
        diff = sum(household_sizes) - N
        household_sizes[len(household_sizes) - 1] = household_sizes[len(household_sizes) - 1] - diff

    local = nx.Graph()
    curr_node = 0
    for household_size in household_sizes:
        household_graph = nx.complete_graph(household_size)

        node_names = dict()
        for node_dex in list(range(household_graph.number_of_nodes())):
            node_names[node_dex] = curr_node
            curr_node += 1

        household_graph = nx.relabel_nodes(household_graph, node_names)

        local.add_nodes_from(household_graph)
        local.add_edges_from(household_graph.edges())

    return local

local = create_local()

"""##ld
Choice one (binomial):
- A binomial graph to represent the long distance connections between households
- For every two nodes of the graph, there is a probability of existing depending on the below parameter, probability_ld_edge.

Choice two (geographic heterogeneity):
- A long-distance connections graph between households (connected components)
- We model distance by having each connected component take a place on a 1D line from 0 to 1. All individuals of the household are assigned this location attribute. The probability of edges existing between individuals of different households depends on this location attribute.
"""

def kernel_func(loc_one, loc_two, sigma):
    prob_from_gaussian_kernel = math.exp(-((np.abs(loc_one - loc_two) / sigma) ** 2))
    return prob_from_gaussian_kernel

def create_ld(type_ld_graph, input_local, probability_ld_edge, sigma):
    if (type_ld_graph == "binomial"):
      ld = nx.fast_gnp_random_graph(N, probability_ld_edge)
    else:
      local = input_local.copy()
      ld = nx.Graph()
      ld.add_nodes_from(local)
      ccs = list((local.subgraph(c) for c in nx.connected_components(local)))
      locations = np.random.uniform(low=0.0, high=1.0, size=len(ccs))
      for cc_one_dex in range(len(ccs)):
        for cc_two_dex in range(cc_one_dex + 1, len(ccs)):
          # Probability of edge from group cc_one_dex and group cc_two_dex -----
          prob_edge = kernel_func(locations[cc_one_dex], locations[cc_two_dex], sigma=sigma)
          # Get all potential edges --------------------------------------------
          potential_edges = list(product(list(ccs[cc_one_dex].nodes()), list(ccs[cc_two_dex].nodes())))
          if (len(potential_edges) != (len(ccs[cc_one_dex].nodes()) * len(ccs[cc_two_dex].nodes()))):
            NameError("Number of potential edges is not correct.")
          # Add edges with some probability ------------------------------------
          for potential_edge in potential_edges:
            edge_exists = (np.random.binomial(n=1, p=prob_edge, size=1)[0] == 1)
            if edge_exists:
              ld.add_edge(potential_edge[0], potential_edge[1])
    return ld

ld = create_ld(type_ld_graph=type_ld_graph_to_use, input_local=local,
               probability_ld_edge=probability_ld_edge, sigma=sigma)

"""## O
- Combine the household connections graph, local, and long distance connections graph, ld, into a single graph, O
- Set the weight for each edge and node for the transitions and transmission parameters with or without heterogeneity
"""

def create_O(local, ld):
    O = nx.Graph()
    O.add_nodes_from(local)
    local_edge_attribute_dict = {edge: local_weight_transmission for edge in local.edges()}
    O.add_edges_from(local.edges())
    ld_edge_attribute_dict = {edge: ld_weight_transmission for edge in ld.edges()}
    O.add_edges_from(ld.edges())
    if ((O.number_of_nodes() != N) | 
        O.number_of_edges() > (local.number_of_edges() + ld.number_of_edges())):
        raise NameError("O is not correct.")
    node_attribute_dict = {node: 1 for node in O.nodes()}
    edge_attribute_dict = {**local_edge_attribute_dict, **ld_edge_attribute_dict}
    nx.set_node_attributes(O, values=node_attribute_dict, name='expose2infect_weight')
    nx.set_edge_attributes(O, values=edge_attribute_dict, name='transmission_weight')
    return [O, node_attribute_dict, edge_attribute_dict]

O_returned = create_O(local=local, ld=ld)
O = O_returned[0]
node_attribute_dict = O_returned[1]
edge_attribute_dict = O_returned[2]

"""## SD
- Create the SD graph out of the O graph by randomly deleting some fraction of the edges of the long distance connections graph, ld
- Save indexes of edges deleted of ld in the global variable: edges_to_delete
"""

def create_SD(local, ld, node_attribute_dict, edge_attribute_dict, percent_edges_to_delete_under_SD_input):
    SD = nx.Graph()
    SD.add_nodes_from(local)
    SD.add_edges_from(local.edges())
    percent_edges_to_delete_under_SD = percent_edges_to_delete_under_SD_input
    edges_to_delete = random.sample(list(range(ld.number_of_edges())), round(ld.number_of_edges() * percent_edges_to_delete_under_SD))
    SD_ld_edges = list(ld.edges)
    for index in sorted(edges_to_delete, reverse=True):
        del SD_ld_edges[index]
    SD.add_edges_from(SD_ld_edges)
    nx.set_node_attributes(SD, values=node_attribute_dict, name='expose2infect_weight')
    nx.set_edge_attributes(SD, values=edge_attribute_dict, name='transmission_weight')
    if ((SD.number_of_nodes() != N) |
        SD.number_of_edges() > (local.number_of_edges() + ld.number_of_edges() - round(ld.number_of_edges() * percent_edges_to_delete_under_SD))):
        raise NameError("SD is not correct.")
    return [SD, edges_to_delete]

"""### Introduce method to add back long distance edges in the future
- Args: SD, frac_add_back
- Return: added_frac_long_SD
- Note 1: the attribute of each edge that is added back will still be in the edge_attribute_dict, so we do not need to worry about losing the edge attribute.
"""

def add_back_long(SD, frac_add_back, edge_attribute_dict, edges_deleted):
    added_frac_long_SD = SD.copy()
    edges_to_add_back = random.choices(edges_deleted, k=round(len(edges_deleted) * frac_add_back))
    for index in edges_to_add_back:
      added_frac_long_SD.add_edge(list(ld.edges())[index][0], list(ld.edges())[index][1])
    nx.set_edge_attributes(added_frac_long_SD, values=edge_attribute_dict, name='transmission_weight')
    return added_frac_long_SD

"""## fuse
- Choice one: create the expanded SD graph by randomly fusing some fraction of the household clusters into pairs
- Choice two: create the expanded SD graph by isolating persons from their household who are infectious

### Introduce method to expand a quarantine circle (i.e. involuntary fusing)
- Args: local, frac_islands_fuse
- Return: expanded_local
- Description: Allow fusing houses with both symptomatic and non-symptomatic individuals.
"""

def expand_local(input_local, frac_islands_fuse):
    local = input_local.copy()
    ccs = list((local.subgraph(c) for c in nx.connected_components(local)))
    ccs_to_expand = random.sample(list(range(len(ccs))), round(len(ccs) * frac_islands_fuse))
    
    # Create array that describes probability of picking each cc based on the 
    # number of nodes (contacts) of the cc. Conserves index of ccs list -------
    probability_choose = []
    for cc_expand_dex in list(range(len(ccs_to_expand))):
        probability_choose.append(ccs[ccs_to_expand[cc_expand_dex]].number_of_nodes())
    
    pairs = list()
    while (len(ccs_to_expand) > 1):
        # Get the index of the island in "ccs_to_expand" and "probability_choose"
        curr_probability_choose = np.divide(probability_choose, sum(probability_choose))
        ccs_to_expand_dex = np.random.choice(a=list(range(len(ccs_to_expand))), size=1, p=curr_probability_choose)
        
        # Get first island, and pop off this element from the probability_choose parallel array
        first_island = ccs_to_expand.pop(ccs_to_expand_dex[0])
        probability_choose.pop(ccs_to_expand_dex[0])
        
        # Get the index of the island in "ccs_to_expand" and "probability_choose"
        curr_probability_choose = np.divide(probability_choose, sum(probability_choose))
        ccs_to_expand_dex = np.random.choice(a=list(range(len(ccs_to_expand))), size=1, p=curr_probability_choose)
        
        # Get second island, and pop off this element from the probability_choose parallel array
        second_island = ccs_to_expand.pop(ccs_to_expand_dex[0])
        probability_choose.pop(ccs_to_expand_dex[0])
        
        pairs.append((first_island, second_island))
    
    # Initialize a dictionary that maps nodes to edge sets created during fusing
    fused_edges_dict = dict()
    
    # Create the modified local graph with fused connected components ----------
    new_local = nx.Graph()
    for pair in pairs:
        island_one = pair[0]
        island_two = pair[1]
        n_nodes = ccs[island_one].number_of_nodes() + ccs[island_two].number_of_nodes()
        
        # Create new complete graph named "temp" that has number of nodes == 
        # number of nodes in island one + number of nodes in island two. Also,
        # "temp" conserves the original node names from the original graph -----
        temp = nx.Graph()
        temp.add_nodes_from(ccs[island_one])
        temp.add_nodes_from(ccs[island_two])
        
        # Create dictionary of the node names from the original island ---------
        node_names = dict()
        for node_dex in list(range(n_nodes)):
            node_names[node_dex] = list(temp.nodes())[node_dex]
        
        # Create the new "fused" connected component ---------------------------
        fused = nx.complete_graph(n_nodes)
        fused = nx.relabel_nodes(fused, node_names)
        
        new_local.add_nodes_from(fused.nodes())
        new_local.add_edges_from(fused.edges())

        # Save the edges that were added in order to fuse the islands ----------
        original_component = nx.compose(ccs[island_one], ccs[island_two])
        added_edges_graph = nx.difference(fused, original_component)
        if fused.number_of_edges() != (added_edges_graph.number_of_edges() + original_component.number_of_edges()):
            NameError("Difference of edges is not correct.")
        
        # Add a key-value entry from each node to the set of edges that should
        # be deleted in the case that the component unfuses --------------------
        for node in added_edges_graph.nodes():
            fused_edges_dict[node] = added_edges_graph.edges()
    
    # Add the ccs that were not chosen to expand -------------------------------
    ccs_not_to_expand = np.setdiff1d(list(range(len(ccs))), ccs_to_expand)
    for cc_num in ccs_not_to_expand:
        new_local.add_nodes_from(ccs[cc_num])
        new_local.add_edges_from(ccs[cc_num].edges())
    
    # Small correction to add in last connected component that may have been
    # chosen to expand, but did not have a pair to expand with ----------------
    if len(ccs_to_expand) == 1:
        last_island = ccs_to_expand[0]
        new_local.add_nodes_from(ccs[last_island])
        new_local.add_edges_from(ccs[last_island].edges())

    return [new_local, fused_edges_dict]

"""### Introduce method to expand a quarantine circle based on whether there is an infection seeded within the component (voluntary fusing)
- Args: local, infected_nodes, frac_islands_fuse
- Return: expanded_local_selected
- Description: only allow fusing houses with no symptomatic individuals.
- Notes: there are minor inefficiencies in the creation of the dictionary for new edges of fused clusters.
"""

def expand_local_select(input_local, infected_nodes, frac_islands_fuse):
    local = input_local.copy()
    ccs = list((local.subgraph(c) for c in nx.connected_components(local)))

    # Find those connected components with at least one currently infected node
    cc_dex = 0
    ccs_infected = []
    for cc in ccs:
      for node in cc.nodes():
        if node in infected_nodes:
          if cc_dex not in ccs_infected:
            ccs_infected.append(cc_dex)
      cc_dex += 1

    # Find the complement ------------------------------------------------------
    ccs_without_infected = np.setdiff1d(list(range(len(ccs))), ccs_infected)

    # Randomly select some of the complement to expand (fuse) ------------------
    ccs_to_expand = random.sample(list(range(len(ccs_without_infected))), round(len(ccs_without_infected) * frac_islands_fuse))
    ccs_to_expand_save = ccs_to_expand.copy()
    pairs = list()
    while (len(ccs_to_expand) > 1):
        first_island_dex = random.randrange(0, len(ccs_to_expand))
        first_island = ccs_to_expand.pop(first_island_dex)
        
        second_island_dex = random.randrange(0, len(ccs_to_expand))
        second_island = ccs_to_expand.pop(second_island_dex)
        
        pairs.append((first_island, second_island))
    
    # Initialize a dictionary that maps nodes to edge sets created during fusing
    fused_edges_dict = dict()

    # Create the modified local graph with fused connected components ----------
    new_local = nx.Graph()
    for pair in pairs:
        island_one = pair[0]
        island_two = pair[1]
        n_nodes = ccs[island_one].number_of_nodes() + ccs[island_two].number_of_nodes()
        
        # Create new complete graph named "temp" that has number of nodes == 
        # number of nodes in island one + number of nodes in island two. Also,
        # "temp" conserves the original node names from the original graph -----
        temp = nx.Graph()
        temp.add_nodes_from(ccs[island_one])
        temp.add_nodes_from(ccs[island_two])
        
        # Create dictionary of the node names from the original island, "temp" -
        node_names = dict()
        for node_dex in list(range(n_nodes)):
            node_names[node_dex] = list(temp.nodes())[node_dex]
        
        # Create the new "fused" connected component ---------------------------
        fused = nx.complete_graph(n_nodes)
        fused = nx.relabel_nodes(fused, node_names)
        
        new_local.add_nodes_from(fused.nodes())
        new_local.add_edges_from(fused.edges())

        # Save the edges that were added in order to fuse the islands ----------
        original_component = nx.compose(ccs[island_one], ccs[island_two])
        added_edges_graph = nx.difference(fused, original_component)
        if fused.number_of_edges() != (added_edges_graph.number_of_edges() + original_component.number_of_edges()):
            NameError("Difference of edges is not correct.")

        # Add a key-value entry from each node to the set of edges that should
        # be deleted in the case that the component unfuses --------------------
        for node in added_edges_graph.nodes():
            fused_edges_dict[node] = added_edges_graph.edges()

    # Add the connected components that have not expanded (fused) --------------
    ccs_not_to_expand = np.setdiff1d(list(range(len(ccs))), ccs_to_expand_save)
    for cc_num in ccs_not_to_expand:
        new_local.add_nodes_from(ccs[cc_num])
        new_local.add_edges_from(ccs[cc_num].edges())
    
    # Small correction to add in last connected component that may have been
    # chosen to expand, but did not have a pair to expand with ----------------
    if len(ccs_to_expand) == 1:
        last_island = ccs_to_expand[0]
        new_local.add_nodes_from(ccs[last_island])
        new_local.add_edges_from(ccs[last_island].edges())
    
    return [new_local, fused_edges_dict]

"""### Create expanded quarantine graph out of SD graph
- Create expanded_local graph by randomly doubling up of the local graph
- Assign edge attributes to new edges of expanded_local graph
- Update global dictionary to included attributes for new edges
- Add the new edges to copy of SD graph
- Add node and edge attributes to expanded_SD graph
"""

def create_expanded_SD(local, SD, 
                       node_attribute_dict, edge_attribute_dict,
                       frac_to_fuse):
    expand_local_return = expand_local(local, frac_to_fuse)
    expanded_local = expand_local_return[0]
    fused_edges_nonselect_dict = expand_local_return[1]
    new_edges = nx.difference(expanded_local, local).edges()
    expanded_edge_attribute_dict = {edge: 0.5+random.random() for edge in new_edges}
    edge_attribute_dict.update(expanded_edge_attribute_dict)
    expanded_SD = SD.copy()
    expanded_SD.add_edges_from(new_edges)
    nx.set_node_attributes(expanded_SD, values=node_attribute_dict, name='expose2infect_weight')
    nx.set_edge_attributes(expanded_SD, values=edge_attribute_dict, name='transmission_weight')
    return[expanded_SD, edge_attribute_dict, fused_edges_nonselect_dict]

"""## unfuse
- Create method to unfuse connected components with some probability if an individual becomes symptomatic
"""

def unfuse_graph(input_graph, symptomatic_nodes, fused_edges_dict, prob_unfuse=0.5):
    graph = input_graph.copy()
    # For each symptomatic individual, there is prob_unfuse probability that the
    # fused connected components they are a part of will unfuse. We find the 
    # edge set that was added during fusing via the fused_edges_dict object ----
    for symptomatic_node in symptomatic_nodes:
        # First, check if it is even part of a fused connected component -------
        if symptomatic_node in fused_edges_dict:
            # Flip a biased coin of p=prob_unfuse to see whether it should unfuse since it
            # is symptomatic
            should_unfuse = np.random.binomial(1, prob_unfuse, 1)
            if (should_unfuse == 1):
                # The following command will not do anything if the edges have
                # already been removed from "graph" --------------------------------
                graph.remove_edges_from(fused_edges_dict[symptomatic_node])
    return graph

"""# Set the parameters of the SEIR epidemic
- Set the spontaneous transition rate parameters and transmission rate parameters for the SEIR simulation
- We base our calculation of beta using the equation of R0 described here: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760158/
"""

H = nx.DiGraph()
H.add_node('S')
H.add_edge('E', 'I', rate = rate_E_I, weight_label='expose2infect_weight')
H.add_edge('I', 'R', rate = rate_I_R)

J = nx.DiGraph()
beta_initial = (R_0 / (((O.number_of_edges() / N) - 1) * (1 / rate_I_R)))
J.add_edge(('I', 'S'), ('I', 'E'), rate = beta_initial, weight_label='transmission_weight')

"""# Run simulations

## Helper method to run the simulation until a certain prevalence
"""

# Helper method to run simulation until a certain prevalence is reached --------
def run_until_prev(input_net, H, J, initial_conditions,
                   prev_start_SD):
    net = input_net.copy()
    next_step_IC = initial_conditions
    t = None
    S = None
    E = None
    I = None
    R = None
    
    curr_prev = 0
    while (curr_prev < prev_start_SD):
        # Run for one time step ------------------------------------------------
        full_net_one_step = EoN.Gillespie_simple_contagion(net, H, J, next_step_IC, return_statuses, tmax = 1, return_full_data=True)    
        t_one_step = full_net_one_step.t()
        S_one_step = full_net_one_step.S()
        E_one_step = full_net_one_step.summary()[1]['E']
        I_one_step = full_net_one_step.I()
        R_one_step = full_net_one_step.R()

        # Concatenate results of the single time step --------------------------
        if ((t is None) and (S is None) and (E is None) and (I is None) and (R is None)):
            t = t_one_step
            S = S_one_step
            E = E_one_step
            I = I_one_step
            R = R_one_step
        else:
            t = np.concatenate((t, (t_one_step + t[-1])), axis=None)
            S = np.concatenate((S, S_one_step), axis=None)
            E = np.concatenate((E, E_one_step), axis=None)
            I = np.concatenate((I, I_one_step), axis=None)
            R = np.concatenate((R, R_one_step), axis=None)
        
        # Get prevalence -------------------------------------------------------
        curr_prev = (E[-1] + I[-1]) / N

        # Get initial conditions for next step of simulation -------------------
        nodes_one_step_final = full_net_one_step.get_statuses(list(range(N)), t_one_step[-1])
        next_step_IC = defaultdict(lambda: 'S')
        for node in range(N):
            status = nodes_one_step_final[node]
            next_step_IC[node] = status

    # Create complete returnable object of simulation --------------------------
    to_add = list()
    to_add.append(t)
    to_add.append(S)
    to_add.append(E)
    to_add.append(I)
    to_add.append(R)

    full_net = full_net_one_step

    last_time_step_dictionary = full_net.get_statuses(time=full_net.t()[-1])
    
    to_return = [last_time_step_dictionary, to_add, t[-1]]
    
    return to_return

"""## Helper method to run the simulation for the relaxation of social distancing events"""

# Helper method to run relaxation of social distancing -----------------------

# The t_O and t_SD arguments are the arrays that track the time passed so far 
# with the original network structure, and the social distancing strucure, 
# respectively -----------------------------------------------------------------

# The t, S, E, I, and R arguments are understood to the arrays that track the 
# time, susceptibles, exposed, infected and recovereds of the simulation so far,
# before relaxation of social distancing is added ------------------------------

# The unfuse argument refers to whether fused connected components will unfuse
# when there is a sign of symptomatic infection within their cluster. This arg
# will not do anything if there are no fused connected components --------------

# The fused_edges_dict arg is a dictionary from nodes to sets of edges that
# were added during the fusing process. If the argument unfuse==True, then the
# fused_edges_dict argument will be used ---------------------------------------

# The length_sim arg refers to the amount of time the simulation should run ----

def add_relaxation(input_net, H, J, initial_conditions,
                   t, S, E, I, R,
                   unfuse,
                   fused_edges_dict,
                   length_sim):
    net = input_net.copy()
    
    # If unfuse, perhaps tedious, but have not found a better way to do it: 
    # check every day for infectious persons in the graph. ---------------------
    if unfuse:
        next_step_IC = initial_conditions
        save_last_R = 0
        while not ((E[-1] == 0 and I[-1] == 0 and R[-1] == save_last_R)):
            save_last_R = R[-1]
            
            # Run for one time step --------------------------------------------
            full_net_one_step = EoN.Gillespie_simple_contagion(net, H, J, next_step_IC, return_statuses, tmax = 1, return_full_data=True)    
            t_one_step = full_net_one_step.t()
            S_one_step = full_net_one_step.S()
            E_one_step = full_net_one_step.summary()[1]['E']
            I_one_step = full_net_one_step.I()
            R_one_step = full_net_one_step.R()

            # Concatenate results of the single time step ----------------------
            t = np.concatenate((t, (t_one_step + t[-1])), axis=None)
            S = np.concatenate((S, S_one_step), axis=None)
            E = np.concatenate((E, E_one_step), axis=None)
            I = np.concatenate((I, I_one_step), axis=None)
            R = np.concatenate((R, R_one_step), axis=None)

            # Get list of nodes that are infectious at the end of this time step
            # as well as get initial conditions for next step of simulation ----
            nodes_one_step_final = full_net_one_step.get_statuses(list(range(N)), t_one_step[-1])
            next_step_IC = defaultdict(lambda: 'S')
            symptomatic_nodes = []
            for node in range(N):
                status = nodes_one_step_final[node]
                next_step_IC[node] = status
                if status == "I":
                    symptomatic_nodes.append(node)

            # Run unfuse method ------------------------------------------------
            net = unfuse_graph(input_graph=net, 
                               symptomatic_nodes=symptomatic_nodes, 
                               fused_edges_dict=fused_edges_dict, 
                               prob_unfuse=prob_unfuse)

        # Create complete returnable object of simulation ----------------------
        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)

        full_net = full_net_one_step
    else:
        full_net = EoN.Gillespie_simple_contagion(net, H, J, initial_conditions, return_statuses, tmax = length_sim, return_full_data=True)    
        t_net = full_net.t()
        S_net = full_net.S()
        E_net = full_net.summary()[1]['E']
        I_net = full_net.I()
        R_net = full_net.R()

        t = np.concatenate((t, (t_net + t[-1])), axis = None)
        S = np.concatenate((S, S_net), axis=None)
        E = np.concatenate((E, E_net), axis=None)
        I = np.concatenate((I, I_net), axis=None)
        R = np.concatenate((R, R_net), axis=None)

        to_add = list()
        to_add.append(t)
        to_add.append(S)
        to_add.append(E)
        to_add.append(I)
        to_add.append(R)
    
    last_time_step_dictionary = full_net.get_statuses(time=full_net.t()[-1])
    
    to_return = [last_time_step_dictionary, to_add]
    
    return to_return

"""## Loop for simulations
- Run stochastic simulations for each SD_day of intervention. Each simulation will run the SEIR epidemic on the O graph until the SD day, then switch to a scenario of relaxation.
"""

# Randomly initialize infections -----------------------------------------------
IC = defaultdict(lambda: 'S')
for node in range(number_of_initial_infected): 
    IC[node] = 'I'

# Prepare loop for simulations -------------------------------------------------
return_statuses = ('S', 'E', 'I', 'R')
cumul_sims_FSD = []
final_status_FSD = []
cumul_sims_EQ = []
final_status_EQ = []
SD_days = []
for iteration in list(range(number_of_simulations)):
    print('Iteration: ' + str(iteration))
    # Create new local graph ---------------------------------------------------
    local = create_local()

    # Create new ld graph ------------------------------------------------------
    ld = create_ld(type_ld_graph="binomial", input_local=local,
                   probability_ld_edge=probability_ld_edge, sigma=sigma)

    # Create new O graph -------------------------------------------------------
    O_returned = create_O(local=local, ld=ld)
    O = O_returned[0]
    node_attribute_dict = O_returned[1]
    edge_attribute_dict = O_returned[2]

    # Calculate number of edges to reduce to have R_t == R_under_SD ------------
    num_ld_SD = N * ((R_under_SD / (beta_initial * (1 / rate_I_R))) + 1) - local.number_of_edges()
    percent_ld_to_delete = 1 - (num_ld_SD / ld.number_of_edges())

    # Create new SD graph ------------------------------------------------------
    SD_returned = create_SD(local=local, ld=ld, 
                            node_attribute_dict=node_attribute_dict, 
                            edge_attribute_dict=edge_attribute_dict,
                            percent_edges_to_delete_under_SD_input=percent_ld_to_delete)
    SD = SD_returned[0]
    edges_deleted = SD_returned[1]
    
    # Calculate number of edges to add to have R_t == R_under_easing -----------
    num_ld_easing = N * ((R_under_easing / (beta_initial * (1 / rate_I_R))) + 1) - local.number_of_edges()
    num_ld_edges_to_add_back = num_ld_easing - num_ld_SD
    percent_ld_to_add_back = num_ld_edges_to_add_back / ld.number_of_edges()
    
    # Create an "easing" graph -------------------------------------------------
    added_frac_long_SD = add_back_long(SD=SD, frac_add_back=percent_ld_to_add_back, 
                                       edge_attribute_dict=edge_attribute_dict, 
                                       edges_deleted=edges_deleted)

    # Create new EQ graph ------------------------------------------------------
    expanded_SD_returned = create_expanded_SD(local=local, SD=added_frac_long_SD, 
                                              node_attribute_dict=node_attribute_dict, 
                                              edge_attribute_dict=edge_attribute_dict,
                                              frac_to_fuse=(frac_to_fuse / 5))
    expanded_SD=expanded_SD_returned[0]
    edge_attribute_dict=expanded_SD_returned[1]
    fused_edges_nonselect_dict=expanded_SD_returned[2]
        
    # First, run on the original graph until certain prevalence ----------------
    returned_run_until_prev = run_until_prev(input_net=O, H=H, J=J, initial_conditions=IC,
                                             prev_start_SD=prev_start_SD)
    t_O = returned_run_until_prev[1][0]
    S_O = returned_run_until_prev[1][1]
    E_O = returned_run_until_prev[1][2]
    I_O = returned_run_until_prev[1][3]
    R_O = returned_run_until_prev[1][4]
    nodes_O_final = returned_run_until_prev[0]
    SD_day = returned_run_until_prev[2]
    SD_days.append(SD_day)
        
    # Next, run on the SD graph ------------------------------------------------
    SD_IC = defaultdict(lambda: 'S')
    for node in range(N):
        SD_IC[node] = nodes_O_final[node]
    full_SD = EoN.Gillespie_simple_contagion(SD, H, J, SD_IC, return_statuses, tmax = sd_to_easing, return_full_data=True)
    t_SD = full_SD.t()
    S_SD = full_SD.S()
    E_SD = full_SD.summary()[1]['E']
    I_SD = full_SD.I()
    R_SD = full_SD.R()
    nodes_SD_final = full_SD.get_statuses(list(range(N)), t_SD[-1])
    
    # Next, run on the added_frac_long_SD graph --------------------------------
    expanded_SD_IC = defaultdict(lambda: 'S')
    for node in range(N):
        expanded_SD_IC[node] = nodes_SD_final[node]
    full_expanded_SD = EoN.Gillespie_simple_contagion(added_frac_long_SD, H, J, expanded_SD_IC, return_statuses, tmax=easing_to_evictions, return_full_data=True)
    t_expanded_SD = full_expanded_SD.t()
    S_expanded_SD = full_expanded_SD.S()
    E_expanded_SD = full_expanded_SD.summary()[1]['E']
    I_expanded_SD = full_expanded_SD.I()
    R_expanded_SD = full_expanded_SD.R()
    nodes_expanded_SD_final = full_expanded_SD.get_statuses(list(range(N)), t_expanded_SD[-1])

    # Combine the time series of the past three network structures (i.e.
    # the epidemic so far) into a single time series ---------------------------
    t = np.concatenate((t_O, (t_SD + t_O[-1])), axis=None)
    S = np.concatenate((S_O, S_SD), axis=None)
    E = np.concatenate((E_O, E_SD), axis=None)
    I = np.concatenate((I_O, I_SD), axis=None)
    R = np.concatenate((R_O, R_SD), axis=None)
    t = np.concatenate((t, (t_expanded_SD + t[-1])), axis=None)
    S = np.concatenate((S, S_expanded_SD), axis=None)
    E = np.concatenate((E, E_expanded_SD), axis=None)
    I = np.concatenate((I, I_expanded_SD), axis=None)
    R = np.concatenate((R, R_expanded_SD), axis=None)
    
    # Create the initial conditions when relaxation is implemented, as well 
    # as get the list of infecteds at day of relaxation ------------------------
    relax_IC = defaultdict(lambda: 'S')
    infected_nodes = []
    for node in range(N):
        status_node = nodes_expanded_SD_final[node]
        relax_IC[node] = status_node
        if status_node == "I":
           infected_nodes.append(node)

    # Next, finish sim on the continued social distancing graph ----------------
    finished_FSD = add_relaxation(input_net=added_frac_long_SD, H=H, J=J, initial_conditions=relax_IC,
                                  t=t, S=S, E=E, I=I, R=R,
                                  unfuse=False,
                                  fused_edges_dict=None,
                                  length_sim=evictions_to_end)
    final_status_FSD.append(finished_FSD[0])
    cumul_sims_FSD.append(finished_FSD[1])
        
    # Next, finish sim on the expanded quarantine graph ------------------------
    t_EQ = t.copy()
    S_EQ = S.copy()
    E_EQ = E.copy()
    I_EQ = I.copy()
    R_EQ = R.copy()
    
    curr_initial_conditions = relax_IC.copy()
    past_fusing_date = evictions_date
    # For all elements of the vector "fusings" ---------------------------------
    for fusing_tuple in fusings:
        # Get eviction date and percent fused on this eviction date ------------
        fusing_date = fusing_tuple[0]
        num_days_run = (fusing_date - past_fusing_date).days
        # Run simulation for rest of month -------------------------------------
        finished_EQ = add_relaxation(input_net=expanded_SD, H=H, J=J, initial_conditions=curr_initial_conditions,
                                     t=t_EQ, S=S_EQ, E=E_EQ, I=I_EQ, R=R_EQ,
                                     unfuse=False,
                                     fused_edges_dict=fused_edges_nonselect_dict.copy(),
                                     length_sim=num_days_run)
        # Update the results up to curr_month ----------------------------------
        t_EQ = finished_EQ[1][0].copy()
        S_EQ = finished_EQ[1][1].copy()
        E_EQ = finished_EQ[1][2].copy()
        I_EQ = finished_EQ[1][3].copy()
        R_EQ = finished_EQ[1][4].copy()
        # Graph for new fusions in the next time step --------------------------
        percent_fused = fusing_tuple[1]
        expanded_SD_returned = create_expanded_SD(local=local, SD=expanded_SD, 
                                                  node_attribute_dict=node_attribute_dict.copy(), 
                                                  edge_attribute_dict=edge_attribute_dict.copy(),
                                                  frac_to_fuse=percent_fused)
        expanded_SD=expanded_SD_returned[0].copy()
        edge_attribute_dict=expanded_SD_returned[1].copy()
        fused_edges_nonselect_dict=expanded_SD_returned[2].copy()
        # Update curr_initial_conditions and past_eviction_date variables ------
        curr_initial_conditions = finished_EQ[0].copy()
        past_fusing_date = fusing_date
    # Run simulation for rest of month -------------------------------------
    num_days_run = (end_date - fusing_date).days
    finished_EQ = add_relaxation(input_net=expanded_SD, H=H, J=J, initial_conditions=curr_initial_conditions,
                                 t=t_EQ, S=S_EQ, E=E_EQ, I=I_EQ, R=R_EQ,
                                 unfuse=False,
                                 fused_edges_dict=fused_edges_nonselect_dict.copy(),
                                 length_sim=num_days_run)
    # Add the results after while loop finished --------------------------------
    final_status_EQ.append(finished_EQ[0])
    cumul_sims_EQ.append(finished_EQ[1])

"""# Plot simulation results
- Plot comparison of simulations of the aforementioned scenarios of relaxed social distancing
"""

if not (path.exists(directory_plots)):
  os.mkdir(directory_plots)

# Find min, median, and max final sizes depending on relaxation type -----------
def find_statistics_final_size(sims):
    final_sizes = []
    for sim_num in list(range(len(sims))):
        sim_final_size = sims[sim_num][4][-1]
        final_sizes.append(sim_final_size)
    median_fs = np.median(final_sizes)
    max_fs = max(final_sizes)
    min_fs = min(final_sizes)
    to_return = [round(((min_fs / N) * 100), 3), round(((median_fs / N) * 100), 3), round(((max_fs / N) * 100), 3)]
    return to_return

# Find min, median, and max paired differences of final sizes ------------------
def find_paired_difference_fs(sims1, sims2):
    differences = []
    for sim_num in list(range(len(sims1))):
        difference = (sims1[sim_num][4][-1] - sims2[sim_num][4][-1])
        differences.append(difference)
    median_fs = np.median(differences)
    max_fs = max(differences)
    min_fs = min(differences)
    to_return = [round(((min_fs / N) * 100), 3), round(((median_fs / N) * 100), 3), round(((max_fs / N) * 100), 3)]
    return to_return

statistics_final_size_FSD = find_statistics_final_size(cumul_sims_FSD)
min_final_size_FSD = statistics_final_size_FSD[0]
median_final_size_FSD = statistics_final_size_FSD[1]
max_final_size_FSD = statistics_final_size_FSD[2]
statistics_final_size_EQ = find_statistics_final_size(cumul_sims_EQ)
min_final_size_EQ = statistics_final_size_EQ[0]
median_final_size_EQ = statistics_final_size_EQ[1]
max_final_size_EQ = statistics_final_size_EQ[2]
paired_difference_fs = find_paired_difference_fs(cumul_sims_EQ, cumul_sims_FSD)
min_paired_difference = paired_difference_fs[0]
median_paired_difference = paired_difference_fs[1]
max_paired_difference = paired_difference_fs[2]

# Prepare legend text ----------------------------------------------------------
black_patch = mpatches.Patch(color='black', label='SD continued; FS %: ' + str(median_final_size_FSD) + ' [' + str(min_final_size_FSD) + ', ' + str(max_final_size_FSD) + ']')
red_patch = mpatches.Patch(color='red', label='involuntary fusing; FS %: ' + str(median_final_size_EQ) + ' [' + str(min_final_size_EQ) + ', ' + str(max_final_size_EQ) + ']')
diff_patch = mpatches.Patch(color='white', label='paired difference FS %: ' + str(median_paired_difference) + ' [' + str(min_paired_difference) + ', ' + str(max_paired_difference) + ']')
param_patch = mpatches.Patch(color='white', label='Network parameters -------------------- \nRt under SD: ' + str(R_under_SD) + '\nRt under easing: ' + str(R_under_easing) + '\n% households fused: ' + str(100 * frac_to_fuse) + '\nSEIR epidemic parameters ------------ \nR0: ' + str(R_0) + '; E to I: ' + str(1 / rate_E_I) + ' days; I to R: ' + str(1 / rate_I_R) + ' days')

# Find min, median and max prevalence after a certain cutoff_day ---------------
def prev_after_day(sims, cutoff_day):
    prevs = []
    for sim_num in list(range(len(sims))):
        if np.where(sims[sim_num][0] >= cutoff_day)[0].size != 0:
            prev_dex = np.where(sims[sim_num][0] >= cutoff_day)[0][0]
            prev = sims[sim_num][4][prev_dex]
            prevs.append(prev)
    if len(prevs) > 0:
        min_prev = min(prevs)
        median_prev = np.median(prevs)
        max_prev = max(prevs)
        to_return = [round(((min_prev / N) * 100), 3), round(((median_prev / N) * 100), 3), round(((max_prev / N) * 100), 3)]
    else:
        to_return = [0, 0, 0]
    return to_return
statistics_prev_FSD = prev_after_day(cumul_sims_FSD, SD_days[0])
min_prev_FSD = statistics_prev_FSD[0]
median_prev_FSD = statistics_prev_FSD[1]
max_prev_FSD = statistics_prev_FSD[2]
statistics_prev_easing = prev_after_day(cumul_sims_FSD, SD_days[0] + sd_to_easing)
min_prev_easing = statistics_prev_easing[0]
median_prev_easing = statistics_prev_easing[1]
max_prev_easing = statistics_prev_easing[2]
statistics_prev_evictions = prev_after_day(cumul_sims_FSD, SD_days[0] + sd_to_easing + easing_to_evictions)
min_prev_evictions = statistics_prev_evictions[0]
median_prev_evictions = statistics_prev_evictions[1]
max_prev_evictions = statistics_prev_evictions[2]
prev_patch = mpatches.Patch(color='white', label='% prev. @ SD intervention: ' + str(median_prev_FSD) + ' [' + str(min_prev_FSD) + ', ' + str(max_prev_FSD) + ']')
prev_patch_two = mpatches.Patch(color='white', label='% prev. @ easing: ' + str(median_prev_easing) + ' [' + str(min_prev_easing) + ', ' + str(max_prev_easing) + ']')
prev_patch_three = mpatches.Patch(color='white', label='% prev. @ evictions: ' + str(median_prev_evictions) + ' [' + str(min_prev_evictions) + ', ' + str(max_prev_evictions) + ']')

SD_day_dex = 0
for sim_num in range(number_of_simulations):
    # Plot the stochastic simulations together --------------------------------
    plt.xlim(0, 500)
    plt.ylim(0, 4)
    plt.ylabel('% N infected')
    plt.xlabel('t')
    plt.title('Prevalence vs. time')
    plt.legend(handles=[black_patch, red_patch, diff_patch, param_patch, prev_patch, prev_patch_two, prev_patch_three], prop={'size': 6})
    plt.plot(cumul_sims_FSD[sim_num][0], 100 * ((cumul_sims_FSD[sim_num][2] + cumul_sims_FSD[sim_num][3]) / N), label='network', color="black", linewidth=0.1)

    if (np.where(cumul_sims_EQ[sim_num][0] >= (SD_days[SD_day_dex] + sd_to_easing + easing_to_evictions))[0].size != 0):
        first_EQ = np.where(cumul_sims_EQ[sim_num][0] >= (SD_days[SD_day_dex] + sd_to_easing + easing_to_evictions))[0][0]
        plt.plot(cumul_sims_EQ[sim_num][0][first_EQ:], 100 * ((cumul_sims_EQ[sim_num][2][first_EQ:] + cumul_sims_EQ[sim_num][3][first_EQ:]) / N), label='network', color="red", linewidth=0.1)
    
    if (np.mod(sim_num + 1, number_of_simulations) == 0):
        plt.axvline(x = SD_days[SD_day_dex])
        plt.axvline(x = (SD_days[SD_day_dex] + sd_to_easing), linestyle='--')
        plt.axvline(x = (SD_days[SD_day_dex] + sd_to_easing + easing_to_evictions), linestyle='--')
        file_name = directory_plots + str(SD_days[SD_day_dex]) + '.png'
        plt.savefig(file_name, dpi=1000)
        plt.clf()
        SD_day_dex += 1
    
    to_save_csv = np.vstack((cumul_sims_FSD[sim_num][0],
                   100 * ((cumul_sims_FSD[sim_num][2] + cumul_sims_FSD[sim_num][3]) / N)))
    to_save_csv = np.vstack((cumul_sims_EQ[sim_num][0][first_EQ:],
                   100 * ((cumul_sims_EQ[sim_num][2][first_EQ:] + cumul_sims_EQ[sim_num][3][first_EQ:]) / N)))
    np.savetxt(directory_plots + str(sim_num) + ".csv", to_save_csv, delimiter=",")

"""# Plot percentage of houses infected and severity of infection for single simulation of involuntary fusing"""

ccs = list((local.subgraph(c) for c in nx.connected_components(local)))

# Helper function to be used in the below plot method --------------------------
def find_severity_household_infection(final_status_dict):
    num_infect_dict = dict()
    num_not_infect_dict = dict()
    for cc_dex in list(range(len(ccs))):
        nodes_of_cc = ccs[cc_dex].nodes()
        num_infect = 0
        num_not_infect = 0
        for node in nodes_of_cc:
            status_of_node = final_status_dict[node]
            if status_of_node == 'R':
                num_infect += 1
            else:
                num_not_infect += 1
        num_infect_dict[cc_dex] = num_infect
        num_not_infect_dict[cc_dex] = num_not_infect
    return [num_infect_dict, num_not_infect_dict]

def plot_final_status(final_status_dict_list):
    num_infect_dict_list = list()
    num_not_infect_dict_list = list()
    for sim_num in list(range(len(final_status_dict_list))):
        returned = find_severity_household_infection(final_status_dict_list[sim_num])
        num_infect_dict_list.append(returned[0])
        num_not_infect_dict_list.append(returned[1])
    
    # Current inefficiency in that not all simulations are plotted -------------
    num_infect_dict = num_infect_dict_list[0]
    num_not_infect_dict = num_not_infect_dict_list[0]

    # Order by size of connected component -------------------------------------
    to_plot_infect = list()
    to_plot_not_infect = list()
    for cc_dex in list(range(len(ccs))):
        to_plot_infect.append(num_infect_dict[cc_dex])
        to_plot_not_infect.append(num_not_infect_dict[cc_dex])

    ind = np.arange(len(ccs))
    width = 0.35
    
    p1 = plt.bar(ind, to_plot_infect, width)
    p2 = plt.bar(ind, to_plot_not_infect, width, bottom=to_plot_infect)
    
    plt.xlabel('household number')
    plt.ylabel('# individuals in household')
    plt.title('infection severity by household')
    plt.yticks(np.arange(0, 18, 10))
    plt.legend((p1[0], p2[0]), ('infected', 'not infected'))

    if not (path.exists(directory_plots)):
        os.mkdir(directory_plots)

    file_name = directory_plots + 'infection_severity.png'
    plt.savefig(file_name, dpi=500)
    plt.clf()

plot_final_status(final_status_EQ)